"""
Trend Analyzer - YouTube íŠ¸ë Œë“œ ë¶„ì„ ì„œë¹„ìŠ¤
"""
import os
import json
import re
from typing import Optional, List, Dict
from googleapiclient.discovery import build
from .ai_service import get_ai_service


class TrendAnalyzer:
    """YouTube íŠ¸ë Œë“œ ë¶„ì„"""

    def __init__(self, ai_provider: str = 'auto'):
        youtube_api_key = os.getenv('YOUTUBE_API_KEY')
        if not youtube_api_key:
            raise ValueError("YOUTUBE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.youtube = build('youtube', 'v3', developerKey=youtube_api_key)
        self.ai_service = get_ai_service(ai_provider)

    def fetch_trending_videos(
        self,
        region: str = 'US',
        category_id: Optional[str] = None,
        max_results: int = 50
    ) -> Dict:
        """YouTube íŠ¸ë Œë”© ë¹„ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°"""

        print(f"ðŸ” {region} ì§€ì—­ì˜ íŠ¸ë Œë”© ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì¤‘... (ìµœëŒ€ {max_results}ê°œ)")

        request = self.youtube.videos().list(
            part='snippet,statistics',
            chart='mostPopular',
            regionCode=region,
            videoCategoryId=category_id,
            maxResults=max_results
        )

        response = request.execute()
        print(f"âœ… {len(response.get('items', []))}ê°œì˜ ë¹„ë””ì˜¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤")

        return response

    def analyze_with_ai(self, video_data: Dict, video_format: str = 'short') -> Dict:
        """AIë¡œ íŠ¸ë Œë“œ ë¶„ì„ (Gemini/Claude ìžë™ ì„ íƒ)"""

        print(f"ðŸ¤– AIë¡œ {video_format} íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")

        # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        video_summaries = []
        for video in video_data.get('items', [])[:20]:  # ìƒìœ„ 20ê°œë§Œ
            snippet = video['snippet']
            stats = video['statistics']

            summary = f"""
ì œëª©: {snippet['title']}
ì¡°íšŒìˆ˜: {stats.get('viewCount', 0)}
ì¢‹ì•„ìš”: {stats.get('likeCount', 0)}
ëŒ“ê¸€: {stats.get('commentCount', 0)}
"""
            video_summaries.append(summary)

        videos_text = "\n---\n".join(video_summaries)

        prompt = f"""
ë‹¤ìŒì€ YouTubeì—ì„œ í˜„ìž¬ íŠ¸ë Œë”© ì¤‘ì¸ {video_format} ì˜ìƒë“¤ìž…ë‹ˆë‹¤.

{videos_text}

ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. ì£¼ìš” í‚¤ì›Œë“œ 10ê°œ (ë°°ì—´)
2. íŠ¸ë Œë”© ì£¼ì œ 5ê°œ (ë°°ì—´)
3. ì¶”ì²œ ì½˜í…ì¸  ì•„ì´ë””ì–´ 3ê°œ (ë°°ì—´)
4. ì˜ˆìƒ ì¡°íšŒìˆ˜ ë²”ìœ„

JSON í˜•ì‹ ì˜ˆì‹œ:
{{
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
    "topics": ["ì£¼ì œ1", "ì£¼ì œ2", ...],
    "content_ideas": ["ì•„ì´ë””ì–´1", "ì•„ì´ë””ì–´2", ...],
    "view_range": "10K-50K"
}}

JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš” (ì¶”ê°€ ì„¤ëª… ì—†ì´).
"""

        response = self.ai_service.generate_text(
            prompt=prompt,
            max_tokens=1000,
            temperature=0.3  # ë¶„ì„ì€ ë‚®ì€ temperature
        )

        # JSON íŒŒì‹±
        analysis = self._parse_json_response(response)

        print(f"âœ… íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ")
        return analysis

    def _parse_json_response(self, response: str) -> Dict:
        """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±"""

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` ì œê±°)
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # ``` ì—†ì´ ì§ì ‘ JSONì´ ì˜¨ ê²½ìš°
            json_str = response

        try:
            analysis = json.loads(json_str)
            return analysis
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "keywords": ["íŠ¸ë Œë“œ", "ì¸ê¸°"],
                "topics": ["ì¼ë°˜"],
                "content_ideas": ["íŠ¸ë Œë“œ ê¸°ë°˜ ì½˜í…ì¸ "],
                "view_range": "ì•Œ ìˆ˜ ì—†ìŒ"
            }

    def get_trending_keywords(
        self,
        region: str = 'US',
        video_format: str = 'short',
        max_results: int = 50
    ) -> List[str]:
        """íŠ¸ë Œë”© í‚¤ì›Œë“œë§Œ ê°„ë‹¨ížˆ ê°€ì ¸ì˜¤ê¸°"""

        videos = self.fetch_trending_videos(region, max_results=max_results)
        analysis = self.analyze_with_ai(videos, video_format)

        return analysis.get('keywords', [])
