"""
Video Producer - ì˜ìƒ ì œìž‘ ì„œë¹„ìŠ¤
"""
import os
import re
from typing import Dict, List, Tuple, Any, Optional
from .tts_service import TTSService
from .audio_processor import AudioProcessor
from .music_library import MusicLibrary
from .image_generator import ImageGenerator


class VideoProducer:
    """ì™„ì „í•œ ì˜ìƒ ì œìž‘ íŒŒì´í”„ë¼ì¸

    TTS, ì˜¤ë””ì˜¤ ì²˜ë¦¬, ë¹„ì£¼ì–¼ ìƒì„±, ìžë§‰, ì˜ìƒ í•©ì„±ì„ í¬í•¨í•œ
    ì „ì²´ ì˜ìƒ ì œìž‘ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    # ìž„ì‹œ ë¹„ì£¼ì–¼ ë°°ê²½ ìƒ‰ìƒ (AI ì´ë¯¸ì§€ ìƒì„± ë¹„í™œì„±í™” ì‹œ ì‚¬ìš©)
    VISUAL_COLORS = [
        (50, 50, 100),   # ì§„í•œ íŒŒëž€ìƒ‰
        (100, 50, 50),   # ì§„í•œ ë¹¨ê°„ìƒ‰
        (50, 100, 50),   # ì§„í•œ ì´ˆë¡ìƒ‰
        (100, 100, 50),  # ë…¸ëž€ìƒ‰
        (100, 50, 100),  # ë³´ë¼ìƒ‰
    ]

    def __init__(self):
        """VideoProducer ì´ˆê¸°í™”"""
        # ë¬´ë£Œ TTS ì‚¬ìš© (gTTS ë˜ëŠ” local)
        tts_provider = os.getenv('TTS_PROVIDER', 'gtts')
        self.tts_service = TTSService(provider=tts_provider)
        self.audio_processor = AudioProcessor()
        self.music_library = MusicLibrary()

        # AI ì´ë¯¸ì§€ ìƒì„± (í˜„ìž¬ëŠ” ë¹„í™œì„±í™”)
        image_provider = os.getenv('IMAGE_PROVIDER', 'none')
        self.image_generator = ImageGenerator(provider=image_provider)

    def produce_video(
        self,
        script: Dict,
        style_preset: str,
        output_path: str
    ) -> Tuple[str, str]:
        """ì™„ì „í•œ ì˜ìƒ ì œìž‘ íŒŒì´í”„ë¼ì¸

        Args:
            script: ëŒ€ë³¸ ì •ë³´ (content, video_format í¬í•¨)
            style_preset: ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ (calm, energetic ë“±)
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ (.mp4)

        Returns:
            Tuple[str, str]: (ì˜ìƒ ê²½ë¡œ, ì¸ë„¤ì¼ ê²½ë¡œ)

        Raises:
            Exception: ì˜ìƒ ì œìž‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        print("\nðŸŽ¬ ì˜ìƒ ì œìž‘ ì‹œìž‘...")

        temp_dir = './temp'
        os.makedirs(temp_dir, exist_ok=True)

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ ìƒì„±
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        # 1. TTS ìŒì„± ìƒì„±
        print("\n1ï¸âƒ£ ìŒì„± ìƒì„± ì¤‘...")
        voice_segments = self.tts_service.generate_with_timestamps(
            script['content'],
            output_dir=os.path.join(temp_dir, 'audio')
        )

        voice_path, voice_duration = self.audio_processor.merge_audio_segments(
            voice_segments,
            os.path.join(temp_dir, 'voice_final.mp3')
        )

        # 2. ë°°ê²½ìŒì•… ì¶”ê°€
        print("\n2ï¸âƒ£ ë°°ê²½ìŒì•… ì¶”ê°€ ì¤‘...")
        background_music_path = self.music_library.get_music_for_style(
            style_preset,
            int(voice_duration)
        )

        if background_music_path:
            adjusted_music_path = os.path.join(temp_dir, 'music_adjusted.mp3')
            self.audio_processor.adjust_audio_length(
                background_music_path,
                voice_duration,
                adjusted_music_path
            )

            final_audio_path = self.audio_processor.mix_voice_and_music(
                voice_path,
                adjusted_music_path,
                os.path.join(temp_dir, 'audio_with_music.mp3'),
                voice_volume=1.0,
                music_volume=0.25
            )
        else:
            final_audio_path = voice_path

        # 3. ì´ë¯¸ì§€/ì˜ìƒ í´ë¦½ ìƒì„±
        print("\n3ï¸âƒ£ ë¹„ì£¼ì–¼ ìƒì„± ì¤‘...")
        visual_clips = self._generate_visual_clips(
            script,
            voice_segments,
            style_preset
        )

        # 4. ìžë§‰ ìƒì„±
        print("\n4ï¸âƒ£ ìžë§‰ ìƒì„± ì¤‘...")
        subtitles = self._create_subtitles(voice_segments)

        # 5. ìµœì¢… í•©ì„±
        print("\n5ï¸âƒ£ ì˜ìƒ í•©ì„± ì¤‘...")
        final_video = self._compose_video(
            visual_clips,
            final_audio_path,
            subtitles,
            script['video_format'],
            voice_duration
        )

        final_video.write_videofile(
            output_path,
            fps=30,
            codec='libx264',
            audio_codec='aac',
            threads=4,
            preset='medium'
        )

        # 6. ì¸ë„¤ì¼ ìƒì„±
        print("\n6ï¸âƒ£ ì¸ë„¤ì¼ ìƒì„± ì¤‘...")
        thumbnail_path = output_path.replace('.mp4', '_thumb.jpg')
        final_video.save_frame(thumbnail_path, t=2)

        print(f"\nâœ… ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}")

        return output_path, thumbnail_path

    def _generate_visual_clips(
        self,
        script: Dict,
        voice_segments: List[Dict],
        style_preset: str
    ) -> List[Any]:
        """ë¹„ì£¼ì–¼ í´ë¦½ ìƒì„±

        AI ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œë„í•˜ë©°, ì‹¤íŒ¨ ì‹œ ë‹¨ìƒ‰ ë°°ê²½ ì‚¬ìš©

        Args:
            script: ëŒ€ë³¸ ì •ë³´
            voice_segments: TTS ì„¸ê·¸ë¨¼íŠ¸ (duration í¬í•¨)
            style_preset: ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹

        Returns:
            List[MoviePy VideoClip]: ë¹„ì£¼ì–¼ í´ë¦½ ë¦¬ìŠ¤íŠ¸

        Raises:
            ImportError: MoviePyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        try:
            # MoviePy 2.x import
            from moviepy import (
                VideoFileClip, ImageClip, ColorClip,
                concatenate_videoclips, CompositeVideoClip,
                AudioFileClip, TextClip
            )
        except ImportError:
            raise ImportError(
                "moviepyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜: pip install moviepy imageio-ffmpeg"
            )

        clips = []

        # AI ì´ë¯¸ì§€ ìƒì„± ì‹œë„ (í™œì„±í™”ëœ ê²½ìš°)
        if self.image_generator.enabled:
            print("\nðŸŽ¨ AI ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            image_paths = self.image_generator.generate_images_for_script(
                voice_segments,
                style_preset,
                './temp/images'
            )
        else:
            image_paths = [None] * len(voice_segments)

        for i, segment in enumerate(voice_segments):
            # ì„¸ê·¸ë¨¼íŠ¸ ì‹¤ì œ ê¸¸ì´ ì‚¬ìš© (ê¸°ë³¸ 5ì´ˆ)
            duration = segment.get('duration', 5.0)
            image_path = image_paths[i]

            # AI ìƒì„± ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë‹¨ìƒ‰ ë°°ê²½
            if image_path and os.path.exists(image_path):
                clip = ImageClip(image_path, duration=duration)
                print(f"âœ… AI ì´ë¯¸ì§€ ì‚¬ìš©: {image_path}")
            else:
                # ë‹¨ìƒ‰ ë°°ê²½ í´ë¦½ ìƒì„±
                color = self.VISUAL_COLORS[i % len(self.VISUAL_COLORS)]
                clip = ColorClip(
                    size=(1920, 1080),
                    color=color,
                    duration=duration
                )

            # ì¤Œ íš¨ê³¼ (ì‹œê°„ì— ë”°ë¼ 1.0ì—ì„œ 1.25ê¹Œì§€ í™•ëŒ€)
            clip = clip.resized(lambda t: 1 + 0.05 * t)

            clips.append(clip)

        return clips

    def _create_subtitles(self, voice_segments: List[Dict]) -> List[Dict]:
        """ìžë§‰ ë°ì´í„° ìƒì„± (TTS ì„¸ê·¸ë¨¼íŠ¸ ì‹¤ì œ ê¸¸ì´ ì‚¬ìš©)"""
        subtitle_data = []

        cumulative_time = 0.0
        for segment in voice_segments:
            # ì„¸ê·¸ë¨¼íŠ¸ ì‹¤ì œ ê¸¸ì´ ì‚¬ìš© (ê¸°ë³¸ê°’ 5ì´ˆ)
            duration = segment.get('duration', 5.0)

            subtitle_data.append({
                'start': cumulative_time,
                'end': cumulative_time + duration,
                'text': segment['text']
            })

            cumulative_time += duration

        return subtitle_data

    def _find_font(self) -> Optional[str]:
        """ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì°¾ê¸°

        Returns:
            Optional[str]: í°íŠ¸ ê²½ë¡œ ë˜ëŠ” None (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
        """
        import platform

        # Windows í°íŠ¸ ê²½ë¡œ
        if platform.system() == 'Windows':
            fonts_dir = r'C:\Windows\Fonts'

            # í•œê¸€ ì§€ì› í°íŠ¸ ìš°ì„  (ë§‘ì€ ê³ ë”•)
            preferred_fonts = [
                os.path.join(fonts_dir, 'malgun.ttf'),     # ë§‘ì€ ê³ ë”•
                os.path.join(fonts_dir, 'malgunbd.ttf'),   # ë§‘ì€ ê³ ë”• Bold
                os.path.join(fonts_dir, 'gulim.ttc'),      # êµ´ë¦¼
                os.path.join(fonts_dir, 'arial.ttf'),      # Arial
                os.path.join(fonts_dir, 'arialbd.ttf'),    # Arial Bold
            ]
        # Linux í°íŠ¸ ê²½ë¡œ
        elif platform.system() == 'Linux':
            preferred_fonts = [
                '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
                '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf',
                '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
            ]
        # macOS í°íŠ¸ ê²½ë¡œ
        elif platform.system() == 'Darwin':
            preferred_fonts = [
                '/System/Library/Fonts/AppleSDGothicNeo.ttc',
                '/Library/Fonts/Arial Bold.ttf',
                '/System/Library/Fonts/Helvetica.ttc',
            ]
        else:
            preferred_fonts = []

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ í°íŠ¸ ë°˜í™˜
        for font_path in preferred_fonts:
            if os.path.exists(font_path):
                print(f"âœ… í°íŠ¸ ë°œê²¬: {font_path}")
                return font_path

        # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        print("âš ï¸ ì‹œìŠ¤í…œ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return None

    def _compose_video(
        self,
        visual_clips: List,
        audio_path: str,
        subtitles: List[Dict],
        video_format: str,
        duration: float
    ):
        """ìµœì¢… ì˜ìƒ í•©ì„±"""

        try:
            # MoviePy 2.x import
            from moviepy import (
                concatenate_videoclips, CompositeVideoClip,
                AudioFileClip, TextClip
            )
        except ImportError:
            raise ImportError("moviepyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install moviepy imageio-ffmpeg")

        # ë¹„ì£¼ì–¼ ì—°ê²°
        video = concatenate_videoclips(visual_clips, method="compose")

        # ì˜ìƒì„ ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§žì¶¤
        if video.duration > duration:
            video = video.subclipped(0, duration)
        elif video.duration < duration:
            # ë§ˆì§€ë§‰ í”„ë ˆìž„ì„ freeze
            last_frame = visual_clips[-1]
            video = concatenate_videoclips([video, last_frame.with_duration(duration - video.duration)])

        # ì˜¤ë””ì˜¤ ì¶”ê°€
        audio = AudioFileClip(audio_path)
        video = video.with_audio(audio)

        # ìžë§‰ ì¶”ê°€ (í°íŠ¸ ê²½ë¡œ ìžë™ íƒì§€)
        font_path = self._find_font()

        def make_textclip(txt):
            return TextClip(
                text=txt,
                font=font_path,
                font_size=50 if video_format == 'short' else 40,
                color='white',
                stroke_color='black',
                stroke_width=2,
                method='caption',
                size=(int(video.w * 0.9), None)
            )

        subtitle_clips = []
        for sub in subtitles:
            txt_clip = make_textclip(sub['text'])
            txt_clip = txt_clip.with_start(sub['start']).with_duration(sub['end'] - sub['start'])
            txt_clip = txt_clip.with_position(('center', 'bottom'))
            subtitle_clips.append(txt_clip)

        video = CompositeVideoClip([video] + subtitle_clips)

        # ìˆí¼ì€ 9:16 í¬ë¡­
        if video_format == 'short':
            video = video.cropped(
                x_center=int(video.w/2),
                y_center=int(video.h/2),
                width=int(video.h * 9/16),
                height=int(video.h)
            )

        return video
