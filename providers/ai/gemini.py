"""
Gemini AI Provider
Google Gemini API wrapper for content generation
"""
import os
import re
import json
from typing import Optional, Dict, Any
from datetime import datetime


class GeminiProvider:
    """Google Gemini API ì œê³µì"""

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        """
        Gemini Provider ì´ˆê¸°í™”

        Args:
            api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: gemini-2.5-flash)
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.model = model or os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')
        self.usage_log = []

        # Google GenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            from google import genai
            self.client = genai.Client(api_key=self.api_key)
        except ImportError:
            raise ImportError(
                "google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "pip install google-genaië¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )

    def generate(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 8000,
        json_mode: bool = False
    ) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
            temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (0.0-1.0)
            max_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜
            json_mode: JSON ì‘ë‹µ ê°•ì œ ì—¬ë¶€

        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        from google.genai import types

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        if system_prompt:
            full_prompt = f"{system_prompt}\n\n{prompt}"
        else:
            full_prompt = prompt

        # JSON ëª¨ë“œì¼ ê²½ìš° í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œ
        if json_mode:
            full_prompt += "\n\nâš ï¸ ë°˜ë“œì‹œ ìˆœìˆ˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json)ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."

        # ìƒì„± ì„¤ì •
        config = types.GenerateContentConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
        )

        # API í˜¸ì¶œ
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=full_prompt,
                config=config
            )

            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            response_text = response.text

            # ì™„ë£Œ ìƒíƒœ í™•ì¸
            if hasattr(response, 'candidates') and response.candidates:
                finish_reason = response.candidates[0].finish_reason
                if finish_reason and finish_reason != 'STOP':
                    print(f"âš ï¸ Gemini ì‘ë‹µì´ ì™„ì „íˆ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {finish_reason}")

            # JSON ëª¨ë“œì¼ ê²½ìš° ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if json_mode:
                response_text = self._clean_json_response(response_text)

            # ì‚¬ìš©ëŸ‰ ë¡œê¹…
            self._log_usage(prompt, response_text, response)

            return response_text

        except Exception as e:
            raise RuntimeError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    def generate_json(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 8000
    ) -> Dict[str, Any]:
        """
        JSON ì‘ë‹µ ìƒì„± ë° íŒŒì‹±

        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            temperature: ì°½ì˜ì„± ìˆ˜ì¤€
            max_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜

        Returns:
            íŒŒì‹±ëœ JSON ë”•ì…”ë„ˆë¦¬

        Raises:
            json.JSONDecodeError: JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ
        """
        response_text = self.generate(
            prompt=prompt,
            system_prompt=system_prompt,
            temperature=temperature,
            max_tokens=max_tokens,
            json_mode=True
        )

        try:
            return json.loads(response_text)
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ğŸ“„ ì›ë³¸ ì‘ë‹µ:\n{response_text}")
            raise

    def _clean_json_response(self, text: str) -> str:
        """
        ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° ë° JSON ì •ì œ

        Args:
            text: ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸

        Returns:
            ì •ì œëœ JSON ë¬¸ìì—´
        """
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
        text = re.sub(r'^```\s*', '', text, flags=re.MULTILINE)
        text = text.strip()

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€)
        match = re.search(r'\{.*\}', text, flags=re.DOTALL)
        if match:
            return match.group(0)

        return text

    def _log_usage(self, prompt: str, response: str, api_response):
        """
        API ì‚¬ìš©ëŸ‰ ë¡œê¹…

        Args:
            prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸
            response: ì¶œë ¥ ì‘ë‹µ
            api_response: Gemini API ì‘ë‹µ ê°ì²´
        """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'model': self.model,
            'prompt_length': len(prompt),
            'response_length': len(response),
        }

        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
        if hasattr(api_response, 'usage_metadata'):
            usage = api_response.usage_metadata
            log_entry['prompt_tokens'] = getattr(usage, 'prompt_token_count', 0)
            log_entry['response_tokens'] = getattr(usage, 'candidates_token_count', 0)
            log_entry['total_tokens'] = getattr(usage, 'total_token_count', 0)

        self.usage_log.append(log_entry)

    def get_usage_stats(self) -> Dict[str, Any]:
        """
        ì‚¬ìš©ëŸ‰ í†µê³„ ë°˜í™˜

        Returns:
            ì‚¬ìš©ëŸ‰ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        if not self.usage_log:
            return {
                'total_calls': 0,
                'total_tokens': 0,
                'estimated_cost': 0.0
            }

        total_calls = len(self.usage_log)
        total_tokens = sum(log.get('total_tokens', 0) for log in self.usage_log)
        total_prompt_tokens = sum(log.get('prompt_tokens', 0) for log in self.usage_log)
        total_response_tokens = sum(log.get('response_tokens', 0) for log in self.usage_log)

        return {
            'total_calls': total_calls,
            'total_tokens': total_tokens,
            'prompt_tokens': total_prompt_tokens,
            'response_tokens': total_response_tokens,
            'estimated_cost': 0.0,  # Geminiì€ í˜„ì¬ ë¬´ë£Œ
            'model': self.model
        }

    def __repr__(self):
        return f"GeminiProvider(model={self.model})"
